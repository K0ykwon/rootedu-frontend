import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    const { message, history } = await request.json();

    if (!message) {
      return NextResponse.json(
        { error: 'ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.' },
        { status: 400 }
      );
    }

    const messages = [
      {
        role: 'system' as const,
        content: `ë‹¹ì‹ ì€ RootEdu ê³µë¶€ ìœ í˜• ì§„ë‹¨ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 16ê°€ì§€ ê³µë¶€ ìœ í˜•ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìƒë“¤ì˜ ê³µë¶€ ìŠ¤íƒ€ì¼ì„ ì§„ë‹¨í•˜ê³  ë§ì¶¤í˜• í•™ìŠµ ì „ëµì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

**16ê°€ì§€ ê³µë¶€ ìœ í˜• (4ì¶• ê¸°ë°˜):**

**1. ê³µë¶€ í™˜ê²½ (Study Environment)**
- ğŸ  ì†”ë¡œí˜• (Solo): í˜¼ì ê³µë¶€í•˜ëŠ” ê²ƒì„ ì„ í˜¸
- ğŸ‘¥ ê·¸ë£¹í˜• (Group): ë‹¤ë¥¸ ì‚¬ëŒê³¼ í•¨ê»˜ ê³µë¶€í•˜ëŠ” ê²ƒì„ ì„ í˜¸

**2. ê³µë¶€ ì ‘ê·¼ ë°©ì‹ (Study Approach)**
- ğŸ“… ê³„íší˜• (Planner): ì²´ê³„ì ì´ê³  ê³„íšì ì¸ ê³µë¶€
- ğŸ”¥ ì¦‰í¥í˜• (Spontaneous): ìƒí™©ì— ë”°ë¼ ì¦‰í¥ì ìœ¼ë¡œ ê³µë¶€

**3. í•™ìŠµ ìŠ¤íƒ€ì¼ (Learning Style)**
- ğŸ§  ì´ë¡ í˜• (Conceptual): ê°œë…ê³¼ ì›ë¦¬ë¥¼ ì¤‘ì‹œ
- ğŸ› ï¸ ì‹¤ì „í˜• (Practical): ì‹¤ì œ ë¬¸ì œí’€ì´ì™€ ì‹¤ìŠµì„ ì¤‘ì‹œ

**4. ì§‘ì¤‘ íŒ¨í„´ (Concentration Pattern)**
- â³ ì¥ì‹œê°„ ëª°ì…í˜• (Marathoner): ì˜¤ë«ë™ì•ˆ ì§‘ì¤‘í•´ì„œ ê³µë¶€
- âš¡ ë‹¨ê¸° ì§‘ì¤‘í˜• (Sprinter): ì§§ì€ ì‹œê°„ì— ì§‘ì¤‘í•´ì„œ ê³µë¶€

**ì‘ë‹µ ìŠ¤íƒ€ì¼:**
- ì¹œê·¼í•˜ê³  ê²©ë ¤ì ì¸ í†¤ ì‚¬ìš©
- í•™ìƒì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ìœ í˜• ì§„ë‹¨
- ìœ í˜•ë³„ ë§ì¶¤ í•™ìŠµ ì „ëµ ì œì‹œ
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
- ì´ëª¨ì§€ë¥¼ í™œìš©í•œ ê°€ë…ì„± ìˆëŠ” ì‘ë‹µ
- í•œêµ­ì–´ë¡œ ì‘ë‹µ

**ì£¼ì˜ì‚¬í•­:**
- í•™ìƒì˜ ë‹µë³€ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìœ í˜• ì§„ë‹¨
- ìœ í˜•ì˜ ì¥ì ê³¼ ë‹¨ì ì„ ê· í˜•ìˆê²Œ ì„¤ëª…
- ê°œì¸ë³„ ë§ì¶¤ í•™ìŠµ ë°©ë²• ì œì‹œ
- í•™ìŠµ í™˜ê²½ê³¼ ìŠ¤íƒ€ì¼ ìµœì í™” ë°©ì•ˆ í¬í•¨

í•­ìƒ í•™ìƒì˜ ê°œì„±ì„ ì¡´ì¤‘í•˜ê³  ìµœì ì˜ í•™ìŠµ ë°©ë²•ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”.`
      },
      ...history.map((msg: any) => ({
        role: msg.role === 'ai' ? 'assistant' : msg.role,
        content: msg.content
      })),
      {
        role: 'user' as const,
        content: message
      }
    ];

    const completion = await openai.chat.completions.create({
      model: 'gpt-4',
      messages,
      max_tokens: 1200,
      temperature: 0.7,
    });

    const response = completion.choices[0]?.message?.content || 'ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';

    return NextResponse.json({ response });

  } catch (error) {
    console.error('OpenAI API ì˜¤ë¥˜:', error);
    return NextResponse.json(
      { error: 'AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    );
  }
}
